{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from utils import imread, im_to_txt_path, isfile\n",
    "from torchvision.transforms import transforms as T\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "parent_dir = 'rois2/'\n",
    "obj_dir = parent_dir + 'objects/'\n",
    "img_dir = parent_dir + 'images/'\n",
    "label_dir = parent_dir + 'labels/'\n",
    "model_dir = parent_dir + 'models/'\n",
    "\n",
    "obj_train_dir = obj_dir + 'train/'\n",
    "obj_test_dir = obj_dir + 'test/'\n",
    "false_positive_label_dir = parent_dir + 'tiles/false_positives/labels/'\n",
    "\n",
    "result_dir = parent_dir + 'results/'\n",
    "result_model1_dir = result_dir + 'model1/'\n",
    "result_model1_test_dir = result_model1_dir + 'test/'\n",
    "\n",
    "result_model1_test_labels_dir = result_model1_test_dir + 'labels/'\n",
    "result_model1_test_images_dir = result_model1_test_dir + 'images/'\n",
    "\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "os.makedirs(result_model1_dir, exist_ok=True)\n",
    "os.makedirs(result_model1_test_dir, exist_ok=True) \n",
    "os.makedirs(result_model1_test_labels_dir, exist_ok=True)\n",
    "os.makedirs(result_model1_test_images_dir, exist_ok=True)\n",
    "\n",
    "mean_std_dict = pickle.load(open(img_dir + 'mean_std.pkl', 'rb'))\n",
    "print(mean_std_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(num_classes=2).to('cuda')\n",
    "\n",
    "classification_model = torchvision.models.efficientnet_b1().to('cuda')\n",
    "classification_model.classifier[1] = nn.Linear(classification_model.classifier[1].in_features, 2).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model1_result(roi_fp, detect_model, save_dir = result_model1_test_labels_dir, window_size=512, stride=256, \n",
    "                      score_thr=0.5, nms_thr=0.5, intersect_thr=0.5,\n",
    "                      box_width_thr = [20,500], box_area_thr = [200,150000], box_ratio_thr = 0.2, clean_up = True):\n",
    "    \n",
    "    if clean_up:\n",
    "        for dirpath, dirnames, filenames in os.walk(result_model1_dir + 'train'):\n",
    "            for filename in [f for f in filenames if f.endswith(\".txt\")]:\n",
    "                os.remove(os.path.join(dirpath, filename))\n",
    "                \n",
    "        for dirpath, dirnames, filenames in os.walk(result_model1_dir + 'test'):\n",
    "            for filename in [f for f in filenames if f.endswith(\".txt\")]:\n",
    "                os.remove(os.path.join(dirpath, filename))\n",
    "    \n",
    "    detect_model.eval()\n",
    "    roi_name = roi_fp.split('/')[-1].split('.')[0]\n",
    "    # print(roi_name)\n",
    "    result_file_path = save_dir + roi_name + '.txt'\n",
    "    result_file = open(result_file_path, 'w')\n",
    "    \n",
    "    orig_roi = imread(roi_fp)\n",
    "    roi_w = orig_roi.shape[1]\n",
    "    roi_h = orig_roi.shape[0]\n",
    "    roi = cv2.copyMakeBorder(orig_roi, 0, window_size - roi_h % window_size, 0, window_size - roi_w % window_size, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    if roi is None:\n",
    "        print('     Error: No roi file found')\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    # load and record groundtruth labels\n",
    "    true_boxes = []\n",
    "    if isfile(im_to_txt_path(roi_fp)):\n",
    "        with open(im_to_txt_path(roi_fp), 'r') as f:\n",
    "            for line in f:\n",
    "                temp_label = [int(x) for x in line.strip().split(' ')]\n",
    "                true_boxes.append([temp_label[1], temp_label[2], temp_label[3], temp_label[4]])\n",
    "    obj_map = torch.zeros((roi_h, roi_w))\n",
    "    for box in true_boxes:\n",
    "        obj_map[box[1]:box[3], box[0]:box[2]] = (box[3] - box[1]) * (box[2] - box[0])\n",
    "    \n",
    "    \n",
    "    print('     roi width: ', roi_w, ' roi height: ', roi_h)\n",
    "    # slide the window from top left to bottom right\n",
    "    start_x = 0\n",
    "    while start_x <= roi_w:\n",
    "        windows = []\n",
    "        offsets = []\n",
    "        \n",
    "        start_y = 0\n",
    "        while start_y <= roi_h: \n",
    "            end_x = int(start_x + window_size)\n",
    "            end_y = int(start_y + window_size)\n",
    "            window = roi[start_y:end_y, start_x:end_x]\n",
    "            window = torch.tensor(window).permute(2,0,1).float().to('cuda')\n",
    "            # print(window.shape)\n",
    "            windows.append(window)\n",
    "            offsets.append([start_x, start_y])\n",
    "            \n",
    "            start_y += stride\n",
    "        # print('     number of windows: ', len(windows))\n",
    "        \n",
    "        \n",
    "        preds = detect_model(windows)\n",
    "        for idx, pred in enumerate(preds):\n",
    "            # window_timer.start()\n",
    "            \n",
    "            offset = offsets[idx]\n",
    "            filtered_idx = torchvision.ops.nms(pred['boxes'], pred['scores'], nms_thr)\n",
    "            # print(\"     Time to perform NMS on current window: \", nms_timer.elapsed_time())\n",
    "            \n",
    "            pred_boxes = pred['boxes'][filtered_idx]\n",
    "            pred_scores = pred['scores'][filtered_idx]\n",
    "            \n",
    "            for score, box in zip(pred_scores,pred_boxes):\n",
    "                # score thr\n",
    "                if score < score_thr:\n",
    "                    continue\n",
    "                \n",
    "                pred_box_x1 = int(box[0] + offset[0])\n",
    "                pred_box_y1 = int(box[1] + offset[1])\n",
    "                pred_box_x2 = int(box[2] + offset[0])\n",
    "                pred_box_y2 = int(box[3] + offset[1])\n",
    "                \n",
    "                # range thr\n",
    "                if pred_box_x1 < 0 or pred_box_y1 < 0 or pred_box_x2 > roi_w or pred_box_y2 > roi_h:\n",
    "                    continue\n",
    "                \n",
    "                #  size thr\n",
    "                if (pred_box_x2 - pred_box_x1) * (pred_box_y2 - pred_box_y1) < box_area_thr[0] \\\n",
    "                    or (pred_box_x2 - pred_box_x1) * (pred_box_y2 - pred_box_y1) > box_area_thr[1] \\\n",
    "                    or pred_box_x2 - pred_box_x1 < box_width_thr[0] or pred_box_x2 - pred_box_x1 > box_width_thr[1] \\\n",
    "                    or pred_box_y2 - pred_box_y1 < box_width_thr[0] or pred_box_y2 - pred_box_y1 > box_width_thr[1] \\\n",
    "                    or (pred_box_x2 - pred_box_x1) * (pred_box_y2 - pred_box_y1) < box_area_thr[0] \\\n",
    "                    or (pred_box_x2 - pred_box_x1) / (pred_box_y2 - pred_box_y1) < box_ratio_thr \\\n",
    "                    or (pred_box_y2 - pred_box_y1) / (pred_box_x2 - pred_box_x1) < box_ratio_thr:\n",
    "                    continue\n",
    "                    \n",
    "                result_file.write(f\"{pred_box_x1} {pred_box_y1} {pred_box_x2} {pred_box_y2}\\n\")\n",
    "        start_x += stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, labels_list, roi_img, mean, std):\n",
    "        \n",
    "        self.labels_list = labels_list\n",
    "        self.roi_img = roi_img\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.inputs_list[idx])\n",
    "        box = self.labels_list[idx]\n",
    "        \n",
    "        obj_img = self.roi_img[box[1]:box[3],box[0]:box[2]]\n",
    "        transf = v2.Compose([\n",
    "            v2.ToImage(), \n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=self.mean, std=self.std),\n",
    "            v2.Resize((260,260)),\n",
    "        ])\n",
    "        output = transf(obj_img)\n",
    "\n",
    "        return output.to('cuda'), box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model1_result_dataloader(pred_labels_fp):\n",
    "    roi_name = pred_labels_fp.split('/')[-1].split('.')[0]\n",
    "    roi_path = img_dir + roi_name + '.png'\n",
    "    \n",
    "    labels_file = open(pred_labels_fp, 'r')\n",
    "    lines = labels_file.readlines()\n",
    "    \n",
    "    labels_list = []\n",
    "    \n",
    "    roi_img = imread(roi_path)\n",
    "    mean, std = mean_std_dict[roi_name]\n",
    "    \n",
    "    for line in lines:\n",
    "        temp_label = [int(x) for x in line.strip().split(' ')]\n",
    "        x1, y1, x2, y2 = int(temp_label[0]), int(temp_label[1]), int(temp_label[2]), int(temp_label[3])\n",
    "        labels_list.append(torch.tensor([x1, y1, x2, y2],dtype = torch.int))\n",
    "        \n",
    "        \n",
    "        \n",
    "    dataset = CustomDataset(labels_list, roi_img, mean, std)\n",
    "    return DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2_result(roi_path, loader, class_model):\n",
    "    roi = imread(roi_path)\n",
    "    \n",
    "    positive_preds = 0\n",
    "    \n",
    "    class_model.eval()\n",
    "    results = []\n",
    "    for i, (imgs,boxes) in enumerate(loader):\n",
    "        if (i + 1) % 10 == 0 or i + 1 == len(loader): \n",
    "            print('     Processing batch[{}/{}]'.format(i+1, len(loader)))\n",
    "        \n",
    "        # print(boxes.shape)\n",
    "        with torch.no_grad():\n",
    "            outputs = class_model(imgs)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            positive_preds += torch.sum(preds == 1).item()\n",
    "            \n",
    "            for idx, pred in enumerate(preds):\n",
    "                if pred == 1:\n",
    "                    # print(idx, len(boxes))\n",
    "                    results.append(boxes[idx].tolist())\n",
    "    \n",
    "    print('     Number of positive predictions: ', positive_preds)\n",
    "    return results\n",
    "                 \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
