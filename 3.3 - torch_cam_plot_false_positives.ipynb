{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "\n",
    "\n",
    "parent_dir = 'rois2/'\n",
    "obj_dir = parent_dir + 'objects/'\n",
    "img_dir = parent_dir + 'images/'\n",
    "label_dir = parent_dir + 'labels/'\n",
    "model_dir = parent_dir + 'models/'\n",
    "\n",
    "obj_train_dir = obj_dir + 'train/'\n",
    "obj_test_dir = obj_dir + 'test/'\n",
    "false_positive_label_dir = parent_dir + 'tiles/false_positives/labels/'\n",
    "if not os.path.exists(obj_dir):\n",
    "    os.makedirs(obj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_dict = pickle.load(open(obj_train_dir + 'mean_std.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_name_to_roi_name(crop_name):\n",
    "    return (crop_name.split('__')[0]).split('\\\\')[-1]\n",
    "\n",
    "def custom_loader(path):\n",
    "    return path\n",
    "\n",
    "class CustomDataset_train(Dataset):\n",
    "\n",
    "    def __init__(self, inputs_list):\n",
    "        \n",
    "        self.inputs_list = inputs_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.inputs_list[idx])\n",
    "        path = self.inputs_list[idx][0]\n",
    "        roi_name = crop_name_to_roi_name(path)\n",
    "        if roi_name in mean_std_dict.keys():\n",
    "            mean, std = mean_std_dict[roi_name]\n",
    "        else:\n",
    "            print('mean std not found')\n",
    "            print(roi_name)\n",
    "            \n",
    "        label = self.inputs_list[idx][1]\n",
    "        image = Image.open(path)\n",
    "        \n",
    "        transf = v2.Compose([\n",
    "            v2.ToTensor(),\n",
    "            v2.Resize((260,260)),\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.RandomVerticalFlip(p=0.5),\n",
    "            v2.RandomAffine(degrees=(0,90), translate=(0.1,0.3), scale=(0.5,0.75)),\n",
    "            v2.Normalize(mean=mean, std=std), # aim to make the mean = 0 and std = 1\n",
    "           \n",
    "        ])\n",
    "        image = transf(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class CustomDataset_test(Dataset):\n",
    "\n",
    "    def __init__(self, inputs_list):\n",
    "        \n",
    "        self.inputs_list = inputs_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.inputs_list[idx])\n",
    "        path = self.inputs_list[idx][0]\n",
    "        roi_name = crop_name_to_roi_name(path)\n",
    "        if roi_name in mean_std_dict.keys():\n",
    "            mean, std = mean_std_dict[roi_name]\n",
    "        else:\n",
    "            print('mean std not found')\n",
    "            print(roi_name)\n",
    "            \n",
    "        label = self.inputs_list[idx][1]\n",
    "        image = Image.open(path)\n",
    "        image.convert('RGB')\n",
    "        \n",
    "        transf = v2.Compose([\n",
    "            v2.ToTensor(),\n",
    "            v2.Resize((260,260)),\n",
    "            v2.Normalize(mean=mean, std=std), \n",
    "        ])\n",
    "        image = transf(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_dataset = datasets.ImageFolder(root=obj_test_dir,loader=custom_loader)\n",
    "test_dataset = CustomDataset_test(orig_test_dataset.samples)\n",
    "val_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_cam_test(model, val_loader, begin_step = 0):\n",
    "    \n",
    "    model.to('cuda')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    print('Validation...')\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Calculate recall\n",
    "    correct_pos_obj = 0\n",
    "    total_pos_obj = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(val_loader):\n",
    "        if i < begin_step:\n",
    "            continue\n",
    "        image = image.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "        \n",
    "        cam_extractor = SmoothGradCAMpp(model, target_layer=model.features[-1])\n",
    "        \n",
    "        output = model(image)\n",
    "        \n",
    "        activation_map = cam_extractor(output.argmax().item(), output)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        total += 1\n",
    "        if (predicted.item() == label.item()):\n",
    "            correct += 1\n",
    "        \n",
    "        if(label.item() == 1):\n",
    "            total_pos_obj += 1\n",
    "            if(predicted.item() == 1):\n",
    "                correct_pos_obj += 1\n",
    "        \n",
    "        # Apply torchCAM to high-score false positive images\n",
    "        \n",
    "        if label == 0 and predicted.item() == 1 and output[0,1].item() > 0.8:\n",
    "            # Resize the CAM and overlay it\n",
    "            result = overlay_mask(to_pil_image(image.squeeze(0)), to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.5)\n",
    "            # Display it\n",
    "            false_positive_cam_dir = obj_dir + 'false_postives_cam/'\n",
    "            if not os.path.exists(false_positive_cam_dir):\n",
    "                os.makedirs(false_positive_cam_dir)\n",
    "            plt.imshow(result); plt.axis('off'); plt.tight_layout()\n",
    "            plt.savefig(false_positive_cam_dir + 'epoch' + '_batch' + str(i) + '.png')\n",
    "            plt.close('all')\n",
    "            \n",
    "        cam_extractor.remove_hooks()\n",
    "        \n",
    "        \n",
    "        if (i+1)%2000 == 0 or i == len(val_loader)-1: \n",
    "            print('      Image [{}/{}], Accuracy: {:.2f} %, Recall: {:.2f} %'\n",
    "                    .format( i+1, len(val_loader), 100 * correct / total, 100 * correct_pos_obj / total_pos_obj))\n",
    "\n",
    "            \n",
    "    print('Accuracy of the network on the validation images: {} % \\n'.format(100 * correct / total))\n",
    "    print('Recall of the network on the validation images: {} % \\n'.format(100 * correct_pos_obj / total_pos_obj))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b1().to('cuda')\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2).to('cuda')\n",
    "model.load_state_dict(torch.load('rois2/models/round3/2024_08_28_lr0.001 decay0.01 weight 1-5/round3_model_epoch17.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\2024summer\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Image [12000/16602], Accuracy: 98.70 %, Recall: 98.89 %\n",
      "      Image [14000/16602], Accuracy: 98.33 %, Recall: 99.28 %\n",
      "      Image [16000/16602], Accuracy: 98.30 %, Recall: 99.06 %\n",
      "      Image [16602/16602], Accuracy: 98.35 %, Recall: 98.89 %\n",
      "Accuracy of the network on the validation images: 98.34898515601333 % \n",
      "\n",
      "Recall of the network on the validation images: 98.89267461669506 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch_cam_test(model, val_loader, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
